{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "536 755\n"
     ]
    }
   ],
   "source": [
    "# pip install opencv-python\n",
    "import cv2\n",
    "img = cv2.imread(\"image01.png\")\n",
    "print(type(img))\n",
    "\n",
    "height, width = img.shape[0:2]\n",
    "print(height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('Original Image', img) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotationMatrix = cv2.getRotationMatrix2D((width/2, height/2), 90, .5)\n",
    "rotatedImage = cv2.warpAffine(img, rotationMatrix, (width, height))\n",
    "\n",
    "cv2.imshow('Rotated Image', rotatedImage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut image\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread(\"image01.png\")\n",
    "height, width = img.shape[0:2]\n",
    "\n",
    "startRow = int(height*.15)\n",
    "startCol = int(width*.15)\n",
    "endRow = int(height*.85)\n",
    "endCol = int(width*.85)\n",
    "\n",
    "croppedImage = img[startRow:endRow, startCol:endCol]\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "\n",
    "cv2.imshow('Cropped Image', croppedImage)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### change size\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread(\"image01.png\")\n",
    "\n",
    "newImg = cv2.resize(img, (0,0), fx=0.75, fy=0.75)\n",
    "\n",
    "cv2.imshow('Resized Image', newImg)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "newImg = cv2.resize(img, (550, 350))\n",
    "cv2.imshow('Resized Image', newImg)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adjust the contrast equation\n",
    "# new_img = a * original_img + b\n",
    "\n",
    "### higher contrast >1\n",
    "### without changes =1\n",
    "### lower contrast [0:1>\n",
    "\n",
    "# b betha. -127 : +127.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"image01.png\")\n",
    "\n",
    "contrast_img = cv2.addWeighted(img, 2.5, np.zeros(img.shape, img.dtype), 0, 0)\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Contrast Image', contrast_img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### blurred image\n",
    "\n",
    "# GaussianBlur() \n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"image01.png\")\n",
    "\n",
    "blur_image = cv2.GaussianBlur(img, (7,7), 0)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "\n",
    "cv2.imshow('Blur Image', blur_image)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Median Blur\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"image01.png\")\n",
    "\n",
    "### 50% noise\n",
    "blur_image = cv2.medianBlur(img,5)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "\n",
    "cv2.imshow('Blur Image', blur_image)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Detect the edges\n",
    "\n",
    "# Canny()\n",
    "### optimal detector\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"image01.png\")\n",
    "#img = cv2.imread(\"stat01.png\")\n",
    "\n",
    "\n",
    "edge_img = cv2.Canny(img,100,200)\n",
    "\n",
    "cv2.imshow(\"Detected Edges\", edge_img)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### grayscale conversion\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread(\"image01.png\")\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "\n",
    "cv2.imshow(\"Gray Scale Image\", gray_img)\n",
    "\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Centroid detection\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"image01.png\")\n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "moment = cv2.moments(gray_img)\n",
    "\n",
    "X = int(moment [\"m10\"] / moment[\"m00\"])\n",
    "\n",
    "Y = int(moment [\"m01\"] / moment[\"m00\"])\n",
    "\n",
    "color = (205, 114, 101)\n",
    "thickness = 1\n",
    "#cv2.circle(img, (X, Y), 15, (205, 114, 101), 1)\n",
    "cv2.circle(img, (X, Y), 15, color, thickness)\n",
    "\n",
    "cv2.imshow(\"Center of the Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### mask for a colored image\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('image01.png')\n",
    "\n",
    "img1 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "gray_img = cv2.medianBlur(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 3)\n",
    "\n",
    "circles = cv2.HoughCircles(gray_img, cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=50, minRadius=0, maxRadius=0)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "            \n",
    "# numpy.full(shape, fill_value, dtype=None, order='C')                  \n",
    "masking=np.full((img1.shape[0], img1.shape[1]),0,dtype=np.uint8)\n",
    "\n",
    "for j in circles[0, :]:\n",
    "    cv2.circle(masking, (j[0], j[1]), j[2], (255, 255, 255), -1)     \n",
    "     \n",
    "# cv2.bitwise_or(background, background, mask=mask)        \n",
    "#final_img = cv2.bitwise_or(img1, img1, masking=masking)\n",
    "final_img = cv2.bitwise_or(img1,img1, masking)\n",
    "\n",
    "cv2.imshow(\"Center of the Image\", final_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Detect and correct skew of text\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"skewed-text-image.png\")\n",
    "\n",
    "### grayscale\n",
    "gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "### invert image\n",
    "gray_img=cv2.bitwise_not(gray_img)\n",
    "\n",
    "### x & y coordinates\n",
    "coordinates = np.column_stack(np.where(gray_img > 0))\n",
    "\n",
    "### calculate tilt angle\n",
    "# -90 : 0\n",
    "ang=cv2.minAreaRect(coordinates)[-1]\n",
    "\n",
    "if ang<-45:\n",
    "    angle=-(90+ang)\n",
    "else:\n",
    "    angle=-ang\n",
    "    \n",
    "height, width = img.shape[:2]\n",
    "center_img = (width / 2, height / 2)\n",
    "\n",
    "rotationMatrix = cv2.getRotationMatrix2D(center_img, angle, 1.0)\n",
    "rotated_img = cv2.warpAffine(img, rotationMatrix, (width, height), borderMode = cv2.BORDER_REFLECT)\n",
    "\n",
    "cv2.imshow(\"Rotated Image\", rotated_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Color detection\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"image01.png\")\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"HSV Image\", hsv_img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "lower_green = np.array([34, 177, 76])\n",
    "upper_green = np.array([255, 255, 255])\n",
    "\n",
    "masking = cv2.inRange(hsv_img, lower_green, upper_green)\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow(\"Green Color detection\", masking)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reduce noise\n",
    "\n",
    "### fastNlMeansDenoising (): Removes noise from a grayscale image\n",
    "### fastNlMeansDenoisingColored (): Removes noise from a colored image\n",
    "### fastNlMeansDenoisingMulti (): Removes noise from grayscale image frames (a grayscale video)\n",
    "### fastNlMeansDenoisingColoredMulti (): Same as 3 but works with colored frames\n",
    "    \n",
    "import cv2\n",
    "img = cv2.imread(\"image01.png\")\n",
    "\n",
    "result = cv2.fastNlMeansDenoisingColored(img,None,20,10,7,21)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "\n",
    "cv2.imshow(\"Denoised Image\", result)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### image outline\n",
    "\n",
    "# findContours()\n",
    "# https://docs.opencv.org/3.4.2/d3/dc0/group__imgproc__shape.html#ga17ed9f5d79ae97bd4c7cf18403e1689a\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('image01.png')\n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "retval, thresh = cv2.threshold(gray_img, 127, 255, 0)\n",
    "\n",
    "img_contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.drawContours(img, img_contours, -1, (0, 255, 0))\n",
    "\n",
    "cv2.imshow('Image Contours', img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Remove the background from an image\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#img = cv2.imread(\"image01.png\")\n",
    "img = cv2.imread(\"stat01.png\")\n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, thresh = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "img_contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "\n",
    "img_contours = sorted(img_contours, key=cv2.contourArea)\n",
    "\n",
    "for i in img_contours:\n",
    "    if cv2.contourArea(i) > 100:\n",
    "        break\n",
    "        \n",
    "mask = np.zeros(img.shape[:2], np.uint8)\n",
    "\n",
    "cv2.drawContours(mask, [i],-1, 255, -1)\n",
    "\n",
    "new_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow(\"Image with background removed\", new_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
